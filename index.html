<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="">
  <meta name="keywords" content="RealDiff">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>RealDiff: Real-world 3D Shape Completion using Self-Supervised Diffusion Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/intro.jpg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
  .paragraph {
    max-height: 100px; /* Set maximum height for collapsed state */
    overflow: hidden; /* Hide overflow */
    transition: max-height 0.3s ease; /* Smooth transition animation */
  }
  .expand-button {
    color: #4895EF;
    cursor: pointer;
  }
</style>

  <style>
  .video-small {
    height: 75%;
  }

  .video-large {

  }

  .intro img{
    display: block;
    margin: 0 auto;
    width: 90%; /* Ensure the image is 70% of its container's width */
    height: auto; /* Maintain aspect ratio */
  }
</style>

</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">RealDiff: Real-world 3D Shape Completion using Self-Supervised Diffusion Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://basakmelisocal.github.io/">Başak Melis Öcal</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/tatarchm/?originalSubdomain=de/">Maxim Tatarchenko</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://karaoglusezer.github.io/">Sezer Karaoğlu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://staff.fnwi.uva.nl/th.gevers/">Theo Gevers</a><sup>1</sup></span>
            </span>
          </div>


          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Amsterdam</span>
            <span class="author-block"><sup>2</sup>Bosch Center for Artificial Intelligence</span>
          </div>


          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper (Coming soon)</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://www.arxiv.org/abs/2409.10180"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!--
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video (Coming soon)</span>
                </a>
              </span>
              -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/RealDiff/RealDiff"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link.
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">RealDiff</span> formulates point cloud completion as a conditional generation problem directly on real-world measurements in a self-supervised way.
      </h2>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Point cloud completion aims to recover the complete 3D shape of an object from partial observations.
            While approaches relying on synthetic shape priors achieved promising results in this domain, their applicability
            and generalizability to real-world data are still limited. To tackle this problem, we propose a self-supervised framework,
            namely RealDiff, that formulates point cloud completion as a conditional generation problem directly on real-world measurements.
          </p>
          <p>
            To better deal with noisy observations without resorting to training on synthetic data, we leverage additional geometric cues.
            Specifically, <span class="dnerf">RealDiff</span> simulates a diffusion process at the missing object parts while conditioning the generation on the partial input to
            address the multimodal nature of the task. We further regularize the training by matching object silhouettes and depth maps,
            predicted by our method, with the externally estimated ones. Experimental results show that our method consistently outperforms
            state-of-the-art methods in real-world point cloud completion.
          </p>
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="pipeline overview">
          <img src="./static/arch.jpg" >
          <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
          <p class="content has-text-justified">When given a pair of noisy point clouds representing an object, our pipeline takes
            one of these point clouds as input, and a pseudo ground-truth is created by combining the two point clouds.
            A diffusion process is simulated at the missing parts (unoccupied input voxels)
            of the voxelized input, while conditioning the generation on the known parts
            (occupied input voxels). To eliminate the noise from the reconstructions, the rendered object
            shapes’ silhouettes and depth maps are constrained
            to match the auxiliary silhouettes (e.g. from ScanNet) and depth maps
            (e.g., from a pre-trained Omnidata model). At generation time, only  <i>f&theta;</i>
            is used to reconstruct a complete 3D shape from the input real-world point cloud.
        </div>
      </div>
    </div>


    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Videos (Coming soon!)</h2>
        <!--<div class="publication-video">
          <iframe src=""
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

        </div>-->
      </div>
    </div>



  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Experiments</h2>
        <div class="pipeline overview">
          <img src="./static/mainres.jpg" >
          <p class="content has-text-justified"><b>Point cloud completion results on the ScanNet dataset at the resolution of 16384 points.</b>
          Experimental results show that the proposed method outperforms the state-of-the-art baselines.
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3"></h2>
        <div class="pipeline overview">
          <img src="./static/realworldresqual.jpg" >
          <p class="content has-text-justified"><b>Visual comparison of point cloud completion results on the ScanNet dataset.</b>
          From left to right: partial shapes sampled from depth images, completion from baselines, our results, and ground-truth CAD model alignments
from Scan2CAD annotations. For multi-modal methods, we picked single output shapes corresponding to a specific random
seed. Our methodology produces reconstructions that are both more comprehensive and adept at retaining the initially
observed structural characteristics.
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3"></h2>
        <div class="pipeline overview">
          <img src="./static/multimodalres.jpg" >
          <p class="content has-text-justified"><b>Multi-modal shape completion on ScanNet dataset with 16384 points.</b>
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3"></h2>
        <div class="pipeline overview">
          <img src="./static/multimodal.jpg" >
          <p class="content has-text-justified"><b>Multimodal completion results for the ScanNet dataset.</b>
          Shapes are ordered from left to right, top to bottom. Our method is able to generate multiple valid outputs across different runs. As the input incompleteness degree rises, the
uncertainty in how to complete the shape geometry also increases which allows for a higher diversity (first, third and fourth
shapes). When a more complete input is provided (second shape), we observe slight changes in the recovered geometry
between different runs.
        </div>
      </div>
    </div>


  </div>
</section>





<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{ocal2024realdiff,
  title={RealDiff: Real-world 3D Shape Completion using Self-Supervised Diffusion Models},
  author={{\"O}cal, Ba{\c{s}}ak Melis and Tatarchenko, Maxim and Karaoglu, Sezer and Gevers, Theo},
  journal={arXiv preprint arXiv:2409.10180},
  year={2024}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            We thank the authors of <a href="https://github.com/nerfies/nerfies.github.io"><span class="dnerf">Nerfies</span></a> that kindly open sourced the template of this website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
